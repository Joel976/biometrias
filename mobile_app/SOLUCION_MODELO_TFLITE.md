# SoluciÃ³n: Error de Shape en Modelo TFLite

**Fecha:** 23 de diciembre de 2025  
**Error:** `Output shape mismatch [1, 3] vs [1, 2]`

---

## ğŸ”´ Problema

Tu modelo TensorFlow Lite (`modelo_oreja.tflite`) tiene **3 clases de salida**, pero el cÃ³digo estaba configurado para **2 clases**.

### Error Original:
```
Invalid argument(s): Output object shape mismatch, 
interpreter returned output of shape: [1, 3] 
while shape of output provided as argument in run is: [1, 2]
```

### Causa:
El modelo fue entrenado con 3 clases en lugar de 2:
- Clase 0: No es oreja
- Clase 1: Oreja (o tal vez "oreja izquierda")
- Clase 2: Oreja (o tal vez "oreja derecha")

---

## âœ… SoluciÃ³n Aplicada

### Cambio en `ear_validator_service.dart`

**ANTES (lÃ­nea 76):**
```dart
var output = List.filled(1 * 2, 0.0).reshape([1, 2]); // âŒ 2 clases
```

**DESPUÃ‰S:**
```dart
var output = List.filled(1 * 3, 0.0).reshape([1, 3]); // âœ… 3 clases
```

### LÃ³gica de ValidaciÃ³n Actualizada:

```dart
// Obtener probabilidades de cada clase
double notEarProb = output[0][0];   // Clase 0: No es oreja
double earProb1 = output[0][1];     // Clase 1: Oreja tipo 1
double earProb2 = output[0][2];     // Clase 2: Oreja tipo 2

// Tomar el mÃ¡ximo como confianza de que sea oreja
double earProbability = max(earProb1, earProb2);
bool isEar = earProbability >= 0.7; // 70% threshold
```

**InterpretaciÃ³n:**
- Si `earProb1` o `earProb2` >= 70% â†’ **ES OREJA** âœ…
- Si ambas < 70% â†’ **NO ES OREJA** âŒ

---

## ğŸ“Š VerificaciÃ³n del Modelo

Para entender mejor quÃ© representa cada clase, verifica el output del modelo:

### Al ejecutar la app, verÃ¡s en la consola:

```
[EarValidator] ğŸ“Š Probabilidades: 
  no_oreja=5.2%, ear1=89.3%, ear2=5.5%
```

**InterpretaciÃ³n:**
- Si `ear1` es alto: modelo detectÃ³ oreja tipo 1
- Si `ear2` es alto: modelo detectÃ³ oreja tipo 2
- Si `no_oreja` es alto: no es una oreja

---

## ğŸ¯ Opciones de ConfiguraciÃ³n

### OpciÃ³n 1: Ajustar el Threshold (Umbral)

Si el modelo es **muy estricto** o **muy permisivo**, ajusta el umbral:

```dart
// En ear_validator_service.dart, lÃ­nea 19
static const double _confidenceThreshold = 0.7; // 70% por defecto

// MÃ¡s permisivo (detecta mÃ¡s orejas, pero con riesgo de falsos positivos):
static const double _confidenceThreshold = 0.5; // 50%

// MÃ¡s estricto (solo orejas muy claras):
static const double _confidenceThreshold = 0.85; // 85%
```

**RecomendaciÃ³n para tu tesis:** Empieza con **0.6 (60%)** y ajusta segÃºn resultados.

---

### OpciÃ³n 2: Verificar Clases del Modelo

Si tienes acceso al cÃ³digo de entrenamiento del modelo, verifica quÃ© representa cada clase:

**Posibles configuraciones:**

#### ConfiguraciÃ³n A: Binaria expandida
```python
# Durante entrenamiento
classes = ['no_ear', 'left_ear', 'right_ear']
# 0: No es oreja
# 1: Oreja izquierda
# 2: Oreja derecha
```

#### ConfiguraciÃ³n B: Multi-clase genÃ©rica
```python
classes = ['background', 'ear', 'other_bodypart']
# 0: Fondo/no oreja
# 1: Oreja
# 2: Otra parte del cuerpo
```

Si conoces la estructura, puedes optimizar la lÃ³gica de detecciÃ³n.

---

### OpciÃ³n 3: Desactivar ValidaciÃ³n Temporalmente

Si el modelo no funciona bien, puedes desactivar la validaciÃ³n mientras lo mejoras:

**En `admin_settings_service.dart`:**

```dart
// Cambiar el valor por defecto
enableEarValidation: false, // Desactivar validaciÃ³n
```

O desde el **Panel de Admin** en la app:
1. Hacer 7 taps en el botÃ³n superior derecho
2. Desactivar "Validar que la imagen sea una oreja"
3. Guardar cambios

Esto permitirÃ¡ registros/login sin validaciÃ³n de IA mientras entrenas un mejor modelo.

---

## ğŸ§  Mejorar el Modelo (Recomendaciones)

Si el modelo rechaza todas las orejas, el problema puede ser:

### 1. Dataset de Entrenamiento Insuficiente
- **Problema:** Pocas imÃ¡genes de orejas
- **SoluciÃ³n:** Aumentar dataset a 500+ imÃ¡genes por clase

### 2. Preprocesamiento Diferente
- **Problema:** El modelo fue entrenado con normalizaciÃ³n diferente
- **Ejemplo:** 
  ```python
  # Durante entrenamiento se usÃ³:
  img = (img - 127.5) / 127.5  # Rango [-1, 1]
  
  # Pero en Flutter usas:
  img = img / 255.0  # Rango [0, 1]
  ```
- **SoluciÃ³n:** Ajustar normalizaciÃ³n en `_imageToTensor()`:

```dart
// En ear_validator_service.dart, lÃ­nea 133
// OPCIÃ“N A: NormalizaciÃ³n 0-1 (actual)
return value / 255.0;

// OPCIÃ“N B: NormalizaciÃ³n -1 a 1 (si el modelo fue entrenado asÃ­)
return (value - 127.5) / 127.5;
```

### 3. Dimensiones Incorrectas
- Verificar que el modelo espera exactamente 224x224x3
- Ver el output al inicializar:
  ```
  [EarValidator] ğŸ“ Input shape: [1, 224, 224, 3]
  [EarValidator] ğŸ“ Output shape: [1, 3]
  ```

---

## ğŸ”§ Testing RÃ¡pido

Para probar si el modelo funciona ahora:

1. **Hot Reload en Flutter:**
   ```bash
   # En la terminal de Flutter
   r  # Hot reload
   ```

2. **Probar captura:**
   - Ir a Login â†’ BiometrÃ­a â†’ Capturar Foto
   - Intentar con una foto de oreja real

3. **Ver logs en consola:**
   ```
   [EarValidator] ğŸ“Š Probabilidades: no_oreja=X%, ear1=Y%, ear2=Z%
   [EarValidator] ğŸ¯ Resultado: ES OREJA / NO ES OREJA
   ```

---

## ğŸ“ Alternativa: Usar Modelo Diferente

Si el problema persiste, puedes usar un modelo pre-entrenado:

### MobileNetV2 (Transfer Learning)
- MÃ¡s robusto
- Requiere re-entrenamiento con tu dataset de orejas
- CÃ³digo Python para entrenar:

```python
import tensorflow as tf

# Cargar modelo base
base_model = tf.keras.applications.MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights='imagenet'
)

# AÃ±adir capas de clasificaciÃ³n
model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(3, activation='softmax')  # 3 clases
])

# Entrenar con tu dataset
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Convertir a TFLite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with open('modelo_oreja_v2.tflite', 'wb') as f:
    f.write(tflite_model)
```

---

## âœ… Estado Actual

**Archivo corregido:** `ear_validator_service.dart`  
**Cambio:** Output shape [1, 2] â†’ [1, 3]  
**Siguiente paso:** Hacer hot reload y probar captura de oreja

**Logs esperados:**
```
[EarValidator] ğŸ“Š Probabilidades: no_oreja=10.0%, ear1=85.0%, ear2=5.0%
[EarValidator] ğŸ¯ Resultado: ES OREJA
[EarValidator] ğŸ“Š Confianza: 85.00%
```

---

## ğŸ“ Para la Tesis

Si el modelo sigue sin funcionar bien, documenta lo siguiente:

**SecciÃ³n 3.6 - ValidaciÃ³n BiomÃ©trica:**

> Durante la validaciÃ³n del modelo TensorFlow Lite para detecciÃ³n de orejas, 
> se identificÃ³ que el modelo pre-entrenado retornaba 3 clases de salida en 
> lugar de las 2 esperadas. Se ajustÃ³ el cÃ³digo de inferencia para manejar 
> correctamente las 3 clases (background, ear_type1, ear_type2), tomando el 
> mÃ¡ximo de confianza entre las clases de oreja como mÃ©trica de validaciÃ³n.
>
> **Umbral de confianza:** 70%  
> **Resultados:** [Documentar tasa de acierto despuÃ©s de ajuste]

---

**Â¡El cÃ³digo ya estÃ¡ corregido!** ğŸ¯  
Haz hot reload (`r` en la terminal de Flutter) y prueba de nuevo.
