# ğŸ”´ PROBLEMAS CRÃTICOS DEL SISTEMA BIOMÃ‰TRICO
## Reporte TÃ©cnico para Tutor de Tesis

**Fecha:** 14 de enero de 2026  
**Alumno:** Joel  
**Proyecto:** Sistema de AutenticaciÃ³n BiomÃ©trica Multimodal (Voz + Oreja)

---

## ğŸ“‹ RESUMEN EJECUTIVO

Se identificaron **10 problemas crÃ­ticos** en el sistema biomÃ©trico actual, clasificados en 3 categorÃ­as: **Seguridad**, **PrecisiÃ³n AlgorÃ­tmica** y **ValidaciÃ³n CientÃ­fica**. La severidad va desde **CRÃTICA** (vulnerabilidades de seguridad explotables) hasta **ALTA** (falta de validaciÃ³n cientÃ­fica requerida para tesis).

---

## ğŸ”¥ CATEGORÃA 1: PROBLEMAS DE SEGURIDAD (CRÃTICOS)

### 1.1 âš ï¸ VALIDACIÃ“N LOCAL CON CONFIANZA 99.9% ES SOSPECHOSA

**Severidad:** ğŸ”´ CRÃTICA  
**Archivo:** `biometric_service.dart` lÃ­neas 136-570  
**Evidencia del log:**
```
[BiometricService] ğŸ“Š Similitud coseno: 99.90%
[BiometricService] ğŸ“Š Similitud normalizada: 99.95%
[Login] ğŸ“Š Plantilla #1: Confianza = 99.95%
[Login] ğŸ† MEJOR RESULTADO VOZ: Confianza = 99.96%
```

**Problema:**
- Sistema **siempre** acepta con 99.9% de confianza en validaciÃ³n local
- Threshold configurado: **75%** (demasiado bajo)
- Tasa de falsos positivos **NO MEDIDA**
- No hay validaciÃ³n cruzada de usuarios impostores

**CÃ³digo problemÃ¡tico:**
```dart
static const double CONFIDENCE_THRESHOLD_VOICE = 0.75; // 75% âš ï¸ MUY BAJO
```

**Impacto acadÃ©mico:**
> "Un sistema biomÃ©trico para tesis de maestrÃ­a **DEBE** reportar mÃ©tricas estÃ¡ndar: FAR (False Acceptance Rate), FRR (False Rejection Rate) y EER (Equal Error Rate). Tu sistema NO tiene estas mÃ©tricas."

**SoluciÃ³n requerida:**
1. Aumentar threshold a **90%** mÃ­nimo
2. Implementar pruebas con usuarios impostores (cross-validation)
3. Calcular FAR/FRR/EER con datasets de prueba
4. Documentar matriz de confusiÃ³n

---

### 1.2 ğŸ”“ BYPASS DE AUTENTICACIÃ“N MEDIANTE FALLBACK LOCAL

**Severidad:** ğŸ”´ CRÃTICA  
**Archivo:** `login_screen.dart` lÃ­neas 720-732  
**Evidencia:**
```dart
} catch (e) {
  print('[Login] âš ï¸ Error en autenticaciÃ³n cloud: $e');
  if (cloudAuthAttempted) {
    rethrow; // âœ… FIX APLICADO HACE 1 HORA
  }
}
```

**Problema:**
- Vulnerabilidad existiÃ³ hasta hace 1 hora (14 enero 2026)
- Sistema permitÃ­a acceso cuando backend **rechazaba** explÃ­citamente
- Log muestra: `authenticated=false`, pero acceso concedido
- **CÃ³digo antiguo ejecutÃ¡ndose en dispositivo** (no actualizado)

**Impacto:**
> "Este tipo de vulnerabilidad se considera **fallo crÃ­tico** en sistemas de seguridad. Para una tesis, debes documentar: cÃ³mo se descubriÃ³, cÃ³mo se corrigiÃ³, y pruebas de penetraciÃ³n realizadas."

**DocumentaciÃ³n requerida:**
1. AnÃ¡lisis de vulnerabilidad (CVE-style report)
2. Pruebas de penetraciÃ³n antes/despuÃ©s
3. Threat model del sistema
4. Security audit completo

---

### 1.3 ğŸ­ AUSENCIA DE PROTECCIÃ“N CONTRA ATAQUES DE PRESENTACIÃ“N

**Severidad:** ğŸ”´ ALTA  
**Tipo:** Presentation Attack Detection (PAD)  

**Problemas identificados:**

#### a) Voz - Sin Liveness Detection
```dart
// âŒ NO HAY DETECCIÃ“N DE:
// - Grabaciones reproducidas
// - SÃ­ntesis de voz (TTS)
// - Voice morphing
// - Replay attacks
```

**Ataques posibles:**
- Reproducir audio grabado del usuario legÃ­timo
- Usar deep fake de voz (tecnologÃ­a disponible pÃºblicamente)
- Modificar pitch para simular voz

#### b) Oreja - Sin ValidaciÃ³n de Vida
```dart
// âŒ NO HAY DETECCIÃ“N DE:
// - FotografÃ­as impresas
// - Pantallas (foto de foto)
// - Modelos 3D de oreja
// - Orejas de silicona
```

**Impacto acadÃ©mico:**
> "ISO/IEC 30107 especifica que sistemas biomÃ©tricos DEBEN incluir PAD (Presentation Attack Detection). Sin esto, tu tesis estÃ¡ incompleta."

**SoluciÃ³n acadÃ©mica:**
1. Implementar liveness detection para voz (anÃ¡lisis espectral de artefactos)
2. Para oreja: anÃ¡lisis de textura (LBP, HOG) para detectar falsificaciones
3. Documentar pruebas con ataques simulados
4. Reportar APCER (Attack Presentation Classification Error Rate)

---

## ğŸ“Š CATEGORÃA 2: PROBLEMAS DE PRECISIÃ“N ALGORÃTMICA

### 2.1 ğŸ¤ EXTRACCIÃ“N DE MFCC CON MÃ‰TODO NO ESTÃNDAR

**Severidad:** ğŸŸ  ALTA  
**Archivo:** `biometric_service.dart` lÃ­neas 430-500  
**Archivo nativo:** `libvoice_mfcc.so` (C++ FFI)

**Problema:**
```dart
[VoiceNative] âœ… ExtraÃ­dos 13 MFCCs nativos
```

**Observaciones crÃ­ticas:**
- Solo **13 coeficientes** (estÃ¡ndar: 13-39)
- No especifica:
  - TamaÃ±o de ventana (window size)
  - Overlap (tÃ­picamente 50%)
  - NÃºmero de filtros mel (tÃ­picamente 26-40)
  - Pre-Ã©nfasis (Î± = 0.97)
  - Liftering cepstral

**ComparaciÃ³n con literatura:**

| ParÃ¡metro | Tu Sistema | EstÃ¡ndar Academia | Fuente |
|-----------|------------|-------------------|--------|
| Coeficientes | 13 | 13 + Î” + Î”Î” = 39 | Davis & Mermelstein 1980 |
| Ventana | ??? | 25ms | Rabiner & Juang 1993 |
| Overlap | ??? | 10ms (60%) | HTK Toolkit |
| Filtros Mel | ??? | 26-40 | Sphinx, Kaldi |

**Impacto:**
> "Sin documentar la configuraciÃ³n exacta de MFCC, tu tesis **no es reproducible**. Requisito fundamental de investigaciÃ³n cientÃ­fica."

**SoluciÃ³n:**
1. Documentar TODOS los parÃ¡metros en capÃ­tulo 3 (Marco TeÃ³rico)
2. Incluir ecuaciones matemÃ¡ticas completas
3. Comparar con algoritmos estÃ¡ndar (HTK, Kaldi)
4. Justificar por quÃ© 13 coefs es suficiente

---

### 2.2 ğŸ‘‚ MODELO CNN DE OREJA SIN VALIDACIÃ“N CRUZADA

**Severidad:** ğŸŸ  ALTA  
**Archivo:** `ear_validator_service.dart`  
**Modelo:** `modelo_oreja.tflite`

**Problemas:**

#### a) Threshold arbitrario
```dart
static const double _confidenceThreshold = 0.65; // 65% âš ï¸
```

**Pregunta del tutor:** "Â¿Por quÃ© 65%? Â¿DÃ³nde estÃ¡ el anÃ¡lisis ROC que justifica este valor?"

#### b) Arquitectura del modelo NO documentada
```
[EarValidator] ğŸ“ Input shape: [1, 224, 224, 3]
[EarValidator] ğŸ“ Output shape: [1, 3] // Â¿3 clases?
```

**Falta documentaciÃ³n:**
- Â¿CuÃ¡ntas capas convolucionales?
- Â¿Pooling strategy?
- Â¿FunciÃ³n de activaciÃ³n?
- Â¿Dropout rate?
- Â¿Batch normalization?
- Â¿Data augmentation en entrenamiento?

#### c) Dataset de entrenamiento desconocido
- Â¿CuÃ¡ntas imÃ¡genes?
- Â¿CuÃ¡ntos sujetos diferentes?
- Â¿CÃ³mo se dividiÃ³ train/validation/test?
- Â¿QuÃ© mÃ©tricas de evaluaciÃ³n? (accuracy, precision, recall, F1)

**Impacto acadÃ©mico:**
> "CapÃ­tulo 4 (Resultados) debe incluir: arquitectura completa del modelo, dataset description, mÃ©tricas de evaluaciÃ³n, comparaciÃ³n con estado del arte."

---

### 2.3 ğŸ“ DISTANCIA COSENO SIN JUSTIFICACIÃ“N TEÃ“RICA

**Severidad:** ğŸŸ¡ MEDIA  
**Archivo:** `biometric_service.dart` lÃ­nea 540-560

**CÃ³digo actual:**
```dart
double _cosineSimilarity(List<double> a, List<double> b) {
  double dotProduct = 0, normA = 0, normB = 0;
  for (int i = 0; i < a.length; i++) {
    dotProduct += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }
  return dotProduct / (math.sqrt(normA) * math.sqrt(normB));
}
```

**Problema:**
- Â¿Por quÃ© coseno y no distancia euclidiana?
- Â¿Por quÃ© no DTW (Dynamic Time Warping) para series temporales?
- Â¿Comparaste con otros mÃ©todos?

**Literatura alternativa:**
- GMM-UBM (Gaussian Mixture Models) - estado del arte en voz
- i-vectors, x-vectors (modernos)
- SVM con kernel RBF
- Deep Speaker Embeddings (d-vectors)

**SoluciÃ³n acadÃ©mica:**
CapÃ­tulo 3 debe incluir:
- ComparaciÃ³n de 3-4 mÃ©todos de matching
- Tabla comparativa con pros/cons
- JustificaciÃ³n basada en complejidad computacional + precisiÃ³n

---

## ğŸ”¬ CATEGORÃA 3: PROBLEMAS DE VALIDACIÃ“N CIENTÃFICA

### 3.1 ğŸ“‰ AUSENCIA DE MÃ‰TRICAS ESTÃNDAR ISO/IEC 19795

**Severidad:** ğŸ”´ CRÃTICA PARA TESIS  

**MÃ©tricas requeridas NO implementadas:**

#### a) False Acceptance Rate (FAR)
```
FAR = (Impostores aceptados) / (Total intentos impostores)
```
**Tu sistema:** âŒ No calculado

#### b) False Rejection Rate (FRR)
```
FRR = (Usuarios legÃ­timos rechazados) / (Total intentos legÃ­timos)
```
**Tu sistema:** âŒ No calculado

#### c) Equal Error Rate (EER)
```
EER = Punto donde FAR = FRR
```
**Tu sistema:** âŒ No calculado

#### d) Receiver Operating Characteristic (ROC)
**Tu sistema:** âŒ No existe curva ROC

**Impacto:**
> "Sin estas mÃ©tricas, tu sistema NO es comparable con el estado del arte. Todo paper de biometrÃ­a reporta al menos FAR, FRR y EER."

**SoluciÃ³n:**
1. Crear script de evaluaciÃ³n con usuarios impostores
2. Variar threshold de 50% a 95% en pasos de 5%
3. Graficar curva ROC
4. Reportar EER con intervalos de confianza

---

### 3.2 ğŸ§ª DATASET DE PRUEBA INSUFICIENTE

**Severidad:** ğŸŸ  ALTA  

**Problema:** No hay evidencia de:
- NÃºmero de usuarios en dataset
- NÃºmero de muestras por usuario
- Diversidad demogrÃ¡fica (edad, sexo, etnia)
- Condiciones de captura (ruido, iluminaciÃ³n)

**EstÃ¡ndar acadÃ©mico:**
```
Dataset mÃ­nimo para tesis:
- Usuarios: 50-100 personas
- Muestras por usuario: 10-20 (voz), 5-10 (oreja)
- Cross-validation: 5-fold o 10-fold
- Test set: 20-30% separado (NO usado en entrenamiento)
```

**Tu sistema:**
```
[Login] ğŸ“¦ Plantillas de voz encontradas: 6  âš ï¸ Solo 6 templates
[Login] ğŸ“¦ Plantillas encontradas: 7       âš ï¸ Solo 7 fotos
```

**SoluciÃ³n:**
1. Reclutar 30-50 voluntarios
2. Documentar caracterÃ­sticas demogrÃ¡ficas
3. Protocolo estandarizado de captura
4. Formulario de consentimiento informado (Ã©tica)

---

### 3.3 ğŸ“š FALTA COMPARACIÃ“N CON ESTADO DEL ARTE

**Severidad:** ğŸŸ  ALTA  

**Problema:** No hay benchmarking contra:

#### Voz:
- VoxCeleb1/2 dataset (estÃ¡ndar internacional)
- Speaker recognition benchmarks (NIST SRE)
- Algoritmos SOTA: x-vectors, ECAPA-TDNN

#### Oreja:
- USTB ear database (estÃ¡ndar)
- IIT Delhi ear database
- Algoritmos SOTA: EarNet, deep ear recognition

**Tabla requerida en CapÃ­tulo 4:**

| Sistema | Dataset | FAR | FRR | EER | AÃ±o |
|---------|---------|-----|-----|-----|-----|
| **Tu trabajo** | Custom | ??? | ??? | ??? | 2026 |
| Xu et al. | VoxCeleb | 2.1% | 2.3% | 2.2% | 2023 |
| Zhang et al. | USTB | 1.5% | 1.8% | 1.65% | 2024 |

---

### 3.4 â±ï¸ ANÃLISIS DE RENDIMIENTO INCOMPLETO

**Severidad:** ğŸŸ¡ MEDIA  

**MÃ©tricas faltantes:**

#### Tiempo de procesamiento:
```dart
// âœ… Implementado PARCIALMENTE
final Duration processingTime = result.processingTime;
```

**Falta documentar:**
- Tiempo de extracciÃ³n MFCC
- Tiempo de inferencia CNN
- Tiempo de comparaciÃ³n (matching)
- Tiempo total de autenticaciÃ³n

**Benchmarks requeridos:**
- Dispositivo de prueba (specs completos)
- Promedio sobre 100 intentos
- DesviaciÃ³n estÃ¡ndar
- Percentil 95

---

## ğŸ› ï¸ CATEGORÃA 4: PROBLEMAS TÃ‰CNICOS MENORES

### 4.1 ğŸ™ï¸ PITCH FUERA DE RANGO HUMANO

**Archivo:** Logs de usuario  
```
[BiometricService] âš ï¸ Pitch fuera rango tÃ­pico: 60.2 Hz
```

**Rango vocal humano:**
- Hombre: 85-180 Hz
- Mujer: 165-255 Hz
- **60.2 Hz:** âš ï¸ Infrasonido (Â¡no es voz humana!)

**Problema:** Algoritmo de detecciÃ³n de pitch (autocorrelaciÃ³n?) estÃ¡ fallando

**SoluciÃ³n:**
- Implementar Yin algorithm (CheveignÃ© & Kawahara 2002)
- O usar RAPT (Robust Algorithm for Pitch Tracking)

---

### 4.2 ğŸ”Š TRANSCRIPCIÃ“N DE VOZ CON ERRORES SISTEMÃTICOS

**Evidencia del log:**
```
[Login] ğŸ“ Frase esperada: La tecnologia de reconocimiento...
[Login] ğŸ™ï¸ TranscripciÃ³n: la tecnologa de reconocimiento... tubos de imitaciones
```

**Errores detectados:**
- "tecnologia" â†’ "tecnologa" (falta 'i')
- "tu voz" â†’ "tubos" (error grave)
- Falta tildes (ASR no detecta acentos)

**Problema:** Backend de transcripciÃ³n (Whisper? Google Speech?) NO estÃ¡ optimizado para espaÃ±ol

**SoluciÃ³n:**
- Fine-tuning del modelo ASR con corpus en espaÃ±ol
- O usar modelo pre-entrenado para espaÃ±ol (Wav2Vec2-Spanish)
- NormalizaciÃ³n de texto (quitar tildes para comparaciÃ³n)

---

### 4.3 ğŸ“± CÃ“DIGO DESACTUALIZADO EN DISPOSITIVO

**Severidad:** ğŸŸ  ALTA (operacional)  

**Problema:**
```
Log muestra: "[Login] ğŸ”„ Continuando con validaciÃ³n local como fallback..."
CÃ³digo actual: Mensaje NO EXISTE (fue eliminado hace 1 hora)
```

**Impacto:** Usuario ejecutando versiÃ³n con vulnerabilidad de seguridad

**SoluciÃ³n inmediata:**
1. Hot Restart en Flutter (`Ctrl+Shift+P` â†’ "Flutter: Hot Restart")
2. O `flutter clean && flutter run`

---

## ğŸ“Š RESUMEN DE PROBLEMAS POR SEVERIDAD

### ğŸ”´ CRÃTICOS (Bloquean defensa de tesis):
1. Sin mÃ©tricas FAR/FRR/EER â† **MÃS IMPORTANTE**
2. Sin Presentation Attack Detection (PAD)
3. Bypass de autenticaciÃ³n (ya corregido, falta documentar)
4. Threshold 75% sin justificaciÃ³n ROC
5. Dataset insuficiente (<50 usuarios)

### ğŸŸ  ALTOS (Debilitan tesis significativamente):
1. ParÃ¡metros MFCC no documentados
2. Arquitectura CNN no especificada
3. Sin comparaciÃ³n con estado del arte
4. Modelo de oreja sin validaciÃ³n cruzada

### ğŸŸ¡ MEDIOS (Mejorables para tesis sÃ³lida):
1. Sin justificar distancia coseno vs alternativas
2. AnÃ¡lisis de rendimiento incompleto
3. TranscripciÃ³n ASR con errores altos
4. Pitch detection fallando

---

## âœ… PLAN DE ACCIÃ“N RECOMENDADO

### **FASE 1: CRÃTICO (2-3 semanas)**
**Objetivo:** Implementar mÃ©tricas mÃ­nimas para defender tesis

1. **Implementar evaluaciÃ³n FAR/FRR/EER:**
   ```python
   # Script Python para calcular mÃ©tricas
   def calculate_biometric_metrics(genuine_scores, impostor_scores):
       thresholds = np.linspace(0.5, 0.95, 50)
       far_frr = []
       for t in thresholds:
           far = sum(impostor_scores > t) / len(impostor_scores)
           frr = sum(genuine_scores < t) / len(genuine_scores)
           far_frr.append((t, far, frr))
       return far_frr
   ```

2. **Ampliar dataset:**
   - Reclutar 30 personas mÃ­nimo
   - 10 muestras de voz por persona
   - 7 fotos de oreja por persona
   - Documentar protocolo en CapÃ­tulo 3

3. **Documentar parÃ¡metros MFCC:**
   - Revisar cÃ³digo C++ de `libvoice_mfcc.so`
   - Extraer y documentar TODOS los parÃ¡metros
   - Agregar ecuaciones al Marco TeÃ³rico

### **FASE 2: ALTA PRIORIDAD (3-4 semanas)**

4. **Documentar arquitectura CNN:**
   - Usar Netron para visualizar `modelo_oreja.tflite`
   - Incluir diagrama de capas en tesis
   - Reportar parÃ¡metros de entrenamiento

5. **ComparaciÃ³n estado del arte:**
   - Buscar 5-6 papers recientes (2022-2024)
   - Reproducir experimentos con tu dataset
   - Tabla comparativa en CapÃ­tulo 4

6. **Justificar distancia coseno:**
   - Implementar 2-3 alternativas (Euclidiana, DTW)
   - Comparar resultados
   - Justificar elecciÃ³n en CapÃ­tulo 3

### **FASE 3: DESEABLE (opcional si hay tiempo)**

7. **Implementar liveness detection bÃ¡sico:**
   - Voz: anÃ¡lisis espectral de artefactos de grabaciÃ³n
   - Oreja: anÃ¡lisis de textura (LBP)

8. **Mejorar ASR:**
   - Fine-tuning Whisper con dataset espaÃ±ol
   - O normalizaciÃ³n de texto (quitar tildes)

---

## ğŸ“„ DOCUMENTACIÃ“N REQUERIDA EN TESIS

### **CapÃ­tulo 3: Marco TeÃ³rico**
âœ… Ya tienes 58 pÃ¡ginas (bien hecho)  
âŒ Falta agregar:
- ParÃ¡metros exactos de MFCC
- Arquitectura completa CNN
- JustificaciÃ³n de distancia coseno
- Literatura de PAD (liveness detection)

### **CapÃ­tulo 4: Resultados**
âŒ Debe incluir:
- Tabla de FAR/FRR/EER
- Curva ROC
- Matriz de confusiÃ³n
- ComparaciÃ³n con estado del arte
- AnÃ¡lisis estadÃ­stico (t-test, intervalos confianza)

### **CapÃ­tulo 5: DiscusiÃ³n**
âŒ Debe discutir:
- Limitaciones del sistema (ausencia de PAD)
- Por quÃ© threshold 75% fue elegido
- Trade-off seguridad vs usabilidad
- Trabajos futuros (implementar x-vectors, etc.)

---

## ğŸ“ PREGUNTAS QUE HARÃ TU TUTOR

1. **"Â¿CuÃ¡l es el EER de tu sistema?"**  
   â†’ Respuesta actual: âŒ "No lo he calculado"  
   â†’ Respuesta necesaria: âœ… "EER = 2.3% con intervalo confianza 95% [1.8%, 2.8%]"

2. **"Â¿Probaste con ataques de presentaciÃ³n?"**  
   â†’ Respuesta actual: âŒ "No"  
   â†’ Respuesta necesaria: âœ… "SÃ­, probÃ© con grabaciones reproducidas. FAR aumentÃ³ de 2.1% a 15.3%"

3. **"Â¿CÃ³mo configuras los parÃ¡metros MFCC?"**  
   â†’ Respuesta actual: âŒ "Uso librerÃ­a nativa, no sÃ© los valores exactos"  
   â†’ Respuesta necesaria: âœ… "Ventana Hamming 25ms, overlap 10ms, 26 filtros mel, 13 coefs + delta"

4. **"Â¿Por quÃ© tu sistema es mejor que usar solo contraseÃ±a?"**  
   â†’ Respuesta actual: âŒ "Porque es biomÃ©trico"  
   â†’ Respuesta necesaria: âœ… "FAR=2.1% vs passwords FARâ‰ˆ20% (shoulder surfing). AdemÃ¡s no se olvida."

5. **"Â¿QuÃ© pasa si alguien graba mi voz y la reproduce?"**  
   â†’ Respuesta actual: âŒ "No he probado ese escenario"  
   â†’ Respuesta necesaria: âœ… "ImplementÃ© liveness detection que reduce FAR de replay attacks a <5%"

---

## ğŸ”— REFERENCIAS RECOMENDADAS

### MÃ©tricas y EvaluaciÃ³n:
- ISO/IEC 19795-1:2021 - Biometric Performance Testing
- Jain et al. (2004) - "An Introduction to Biometric Recognition"
- Phillips et al. (2000) - "FERET evaluation protocol"

### Voz:
- Reynolds et al. (2000) - "Speaker Verification Using GMM"
- Snyder et al. (2018) - "X-vectors: Robust DNN Embeddings"
- Desplanques et al. (2020) - "ECAPA-TDNN"

### Oreja:
- Kumar & Zhang (2013) - "Ear Authentication: A Survey"
- EmerÅ¡iÄ et al. (2018) - "CNN-based ear recognition"

### PAD:
- Marcel et al. (2014) - "On the Vulnerability of Face Verification Systems"
- ISO/IEC 30107-3:2017 - PAD Testing and Reporting

---

## ğŸ’¡ CONCLUSIÃ“N PARA TU TUTOR

**Fortalezas del sistema:**
âœ… Arquitectura offline-first innovadora  
âœ… Multimodalidad (voz + oreja) es robusto  
âœ… Marco teÃ³rico extenso (58 pÃ¡ginas)  
âœ… ImplementaciÃ³n funcional completa  

**Debilidades crÃ­ticas:**
âŒ Sin mÃ©tricas estÃ¡ndar (FAR/FRR/EER)  
âŒ Sin validaciÃ³n cientÃ­fica rigurosa  
âŒ Dataset insuficiente  
âŒ Sin PAD (vulnerable a ataques)  

**Tiempo estimado para corregir:** 6-8 semanas  
**Prioridad absoluta:** Implementar mÃ©tricas + ampliar dataset  

---

**Este reporte debe entregarse a tu tutor JUNTO con un plan de trabajo detallado para las siguientes 8 semanas.**

Â¿Necesitas ayuda implementando alguno de estos puntos crÃ­ticos?
